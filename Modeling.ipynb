{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6cb6fe-91a6-4a09-8e67-436167623fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.3f}') \n",
    "import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize']=(20,8)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# 기존 코드\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "# 새로운 코드\n",
    "# ax = plt.gca()  # 현재 축을 가져옵니다.\n",
    "# ax.xaxis.set_major_locator(ticker.MultipleLocator(24))  # x축의 주요 눈금을 24마다 설정합니다.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def setting_styles_basic():\n",
    "    from matplotlib import rcParams # 한글 환경 설정을 위한 rcParams 임포트\n",
    "    rcParams['font.family'] = 'Malgun Gothic'\n",
    "    rcParams['axes.unicode_minus'] = False # 한글 폰트 사용 시, 마이너스 기호가 깨지는 현상 방지\n",
    "\n",
    "setting_styles_basic()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.tsa.stattools import grangercausalitytests\n",
    "# from statsmodels.tsa.vector_ar.var_model import VAR,LagOrderResults\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM,select_coint_rank, select_order,coint_johansen\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa import seasonal\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1404d-fce1-4a9f-a9f6-c95688cdd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./merged_dataset.csv', index_col=0)\n",
    "# df['datetime']=pd.to_datetime(df['datetime'])\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816029d-2048-4369-8b1c-e2ce913ecfa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['datetime']=pd.to_datetime(df['datetime'])\n",
    "data=df.groupby(['data_block_id','datetime','is_consumption']).mean()[['target','direct_solar_radiation_f','surface_solar_radiation_downwards_f',\n",
    "                                                              'cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f','cloudcover_total_f',\n",
    "                                                              'dewpoint_f','temperature_f']]\n",
    "data=data.reset_index().set_index('datetime')\n",
    "data_prod=data[data['is_consumption']==0]\n",
    "for col in data_prod.drop(['data_block_id','is_consumption'], axis=1).columns:\n",
    "    sns.lineplot(data_prod,x=data_prod.index, y=col, color='sandybrown')\n",
    "    plt.title(f'{col}_original')\n",
    "    plt.show()\n",
    "    sns.lineplot(data_prod.diff(24).dropna(),x=data_prod.index[24:], y=col, color='forestgreen')\n",
    "    plt.title(f'{col}_diff24')\n",
    "    plt.show()\n",
    "    data_prod_sc=pd.DataFrame(StandardScaler().fit_transform(data_prod.diff(24).dropna()), columns=data_prod.diff(24).dropna().columns,\n",
    "                             index=data_prod.diff(24).dropna().index)\n",
    "    sns.lineplot(data_prod_sc, x=data_prod_sc.index, y=col, color='coral')\n",
    "    plt.title(f'{col}_diff24_standard')\n",
    "    plt.show()\n",
    "    # sns.lineplot(data_prod.diff(24).dropna(),x=data_prod.index[24:], y=col, color='blueviolet')\n",
    "    # plt.title(f'{col}_diff24')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb7a4d-01b0-451c-9bf8-d7a5d2a4d323",
   "metadata": {},
   "source": [
    "# VECMX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665e140-0280-4c02-a69d-4acee7fc5ba8",
   "metadata": {},
   "source": [
    "## 함수 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ed5fe-34e9-4907-9523-8b803f2ba136",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column, diff=24): # \n",
    "    print(f'소비여부: {bool(is_consumption)}, 프로슈머유형: {prediction_unit_id}, 테스트날짜: {test_data_block_id}')\n",
    "    # datetime을 시간 주기 datetime 객체로 변환\n",
    "    df['datetime']=pd.to_datetime(df['datetime'])\n",
    "    df['datetime_H'] = pd.DatetimeIndex(df['datetime']).to_period('H')\n",
    "    # 조건에 맞는 데이터프레임만 가져오기 + 시간 인덱스 설정\n",
    "    df=df[((df['is_consumption']==is_consumption)&(df['prediction_unit_id']==prediction_unit_id))].set_index('datetime_H')\n",
    "    # 타겟 및 시간 컬럼을 제외한 사용 컬럼에 대한 24차분을 통해 하루전날 대비 변화량으로 표현\n",
    "    if diff:\n",
    "        data=df[variables_columns].diff(diff) # .drop(target_column, axis=1)\n",
    "        \n",
    "    # data_block_id를 따오기\n",
    "    data['data_block_id']=df['data_block_id']\n",
    "    # # 타겟 컬럼추가\n",
    "    # data[target_column]=df[target_column]\n",
    "    data=data.dropna()\n",
    "\n",
    "    # 지구 자전 컬럼 추가\n",
    "    data['earth_rotation_degree']=data.index.hour.values\n",
    "    data['earth_rotation_degree']=data['earth_rotation_degree'].apply(lambda x: x if x<=12 else 24-x)\n",
    "\n",
    "    # 지구의 태양 공전 궤도를 0~1 사이로 스케일링\n",
    "    def scale_date(year, dayofyear):\n",
    "        def solstice_date(year):\n",
    "            return 90 + 0.2422 * (year - 2000) - (year - 2000) // 4\n",
    "        \n",
    "        # 하지와 동지의 태양력 날짜를 구하기\n",
    "        summer_solstice = solstice_date(year) \n",
    "        winter_solstice = solstice_date(year) + 181\n",
    "    \n",
    "        # 태양력으로 된 날짜를 하지를 최대값으로, 동지를 최소값으로 하여 스케일링하기\n",
    "        scaled_date = (dayofyear - winter_solstice) / (summer_solstice - winter_solstice)\n",
    "    \n",
    "        # 스케일링된 날짜를 반환하기\n",
    "        return scaled_date    \n",
    "    # 지구의 태양 공전 컬럼 추가\n",
    "    data['earth_orbit_degree']=scale_date(data.index.year, data.index.dayofyear)\n",
    "    \n",
    "\n",
    "    \n",
    "    # train=data[data['data_block_id']<=369].drop('data_block_id', axis=1) ### 1년만 학습 -> 결과 구데기임. \n",
    "    train=data.drop(data[data['data_block_id']>=test_data_block_id].index).drop('data_block_id', axis=1) ### data_block_id를 바꿈. 테스트 이후의 날짜는 사용하면 안돼\n",
    "    test=data[data['data_block_id']==test_data_block_id].drop('data_block_id', axis=1) ############################ original(하루 예측용)\n",
    "    # test=data[data['data_block_id']>=test_data_block_id].drop('data_block_id', axis=1) ############################ modify(634이후 4일 예측용)\n",
    "    \n",
    "\n",
    "    print('columns: ', train.columns)\n",
    "    return train, test\n",
    "\n",
    "def scale_time_df(train, test, target_column):\n",
    "    x_scaler=StandardScaler()\n",
    "    train_sc=pd.DataFrame(x_scaler.fit_transform(train.drop(target_column, axis=1)), index=train.index, \n",
    "                                                   columns= train.drop(target_column, axis=1).columns)\n",
    "    test_sc=pd.DataFrame(x_scaler.transform(test.drop(target_column, axis=1)), index=test.index,\n",
    "                          columns=test.drop(target_column, axis=1).columns)\n",
    "\n",
    "    def relu(x):\n",
    "        return np.max(x,0)\n",
    "    \n",
    "    train_sc['earth_rotation_degree']=train_sc['earth_rotation_degree'].apply(lambda x: relu(x)) ##### relu 통해서 야간 시단개의 영향력을 제거\n",
    "    test_sc['earth_rotation_degree']=test_sc['earth_rotation_degree'].apply(lambda x: relu(x)) ##### relu 통해서 야간 시단개의 영향력을 제거\n",
    "\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_sc=pd.Series(y_scaler.fit_transform(train[target_column].values.reshape(-1,1))[:,0], index=train.index)\n",
    "    y_test_sc=pd.Series(y_scaler.transform(test[target_column].values.reshape(-1,1))[:,0], index=test.index)\n",
    "\n",
    "    \n",
    "    train_sc['target']=y_train_sc\n",
    "    test_sc['target']=y_test_sc\n",
    "\n",
    "    return train_sc, test_sc, y_scaler\n",
    "\n",
    "def vecmx_modeling(train_df, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                   n_order=False, maxlags=None, deterministic='n'):\n",
    "    if n_order:\n",
    "        lag_order = select_order(train_df[endog_columns], maxlags=maxlags, deterministic=deterministic)\n",
    "        print('best aic lag order: ', lag_order.aic)\n",
    "        k_ar_diff=lag_order.aic\n",
    "\n",
    "    print('k_ar_diff: ', k_ar_diff)\n",
    "    coint_result=statsmodels.tsa.vector_ar.vecm.select_coint_rank(train_df[endog_columns], k_ar_diff=k_ar_diff, det_order=-1)\n",
    "    coint_rank=coint_result.rank\n",
    "    print('coint_rank: ', coint_rank)\n",
    "    print(coint_result)\n",
    "\n",
    "    if exog_columns and exog_coint_columns: \n",
    "        model=VECM(endog=train_df[endog_columns], exog=train_df[exog_columns], exog_coint=train_df[exog_coint_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    elif exog_columns and not exog_coint_columns:\n",
    "        model=VECM(endog=train_df[endog_columns], exog=train_df[exog_columns],\n",
    "               k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    elif not exog_columns and exog_coint_columns:\n",
    "        model=VECM(endog=train_df[endog_columns], exog_coint=train_df[exog_coint_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    else:\n",
    "        model=VECM(endog=train_df[endog_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "        \n",
    "    model_fit=model.fit()\n",
    "    \n",
    "    if not(exog_columns or exog_coint_columns):\n",
    "        # ax = plt.gca()  # 현재 축을 가져옵니다.\n",
    "        # ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
    "        model_fit.plot_forecast(steps=24, n_last_obs=96,plot_conf_int=False)\n",
    "        plt.show()\n",
    "        \n",
    "    return model_fit\n",
    "\n",
    "# 만들어진 모델로 예측해줌. 예측값을 다시 원래의 스케일로 되돌려서 반환.\n",
    "def vecmx_predicting(model_fit, y_scaler,test_sc=None,exog_columns=None, exog_coint_columns=None, steps=24, nth_day=0):\n",
    "    if exog_columns and exog_coint_columns: \n",
    "        y_pred=model_fit.predict(steps=steps, exog_coint_fc=test_sc[exog_coint_columns].iloc[nth_day*steps:nth_day*steps+steps], \n",
    "                             exog_fc=test_sc[exog_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    elif exog_columns and not exog_coint_columns:\n",
    "        y_pred=model_fit.predict(steps=steps, \n",
    "                             exog_fc=test_sc[exog_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    elif not exog_columns and exog_coint_columns:\n",
    "        y_pred=model_fit.predict(steps=steps, exog_coint_sc=test_df[exog_coint_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    else:\n",
    "        y_pred=model_fit.predict(steps=steps)\n",
    "\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# r2, mae, rmse 평가지표 뽑아주고, test용 data_block_id에 해당하는 날에 대한 그래프 그려주고, 시간을 인덱스로 실제값, 시간, 예측값을 담은 데이터 프레임 반환해줌.\n",
    "def vecmx_evaluating(test,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False): \n",
    "    \n",
    "    endog_test=test[endog_columns]\n",
    "    test_df=endog_test.iloc[nth_day*steps:nth_day*steps+steps]\n",
    "    test_df['prediction']=y_pred[:,target_location]\n",
    "\n",
    "    r2=r2_score(test_df['target'],test_df['prediction'])\n",
    "    mae=mean_absolute_error(test_df['target'],test_df['prediction'])\n",
    "    rmse= np.sqrt(mean_squared_error(test_df['target'],test_df['prediction']))\n",
    "    \n",
    "    print('r2_score: ', r2)\n",
    "    print('mae: ', mae)\n",
    "    print('rmse: ', rmse)\n",
    "    \n",
    "    dt=test_df.index[0]\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    dt=f'{year}년_{month}월_{day}일'\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    sns.lineplot(test_df, x=test_df.index.to_timestamp(), y='target', label='actual', color='tomato') # 최애 색: tamato, deepskyblue\n",
    "    sns.lineplot(test_df, x=test_df.index.to_timestamp(), y='prediction', label='prediction', color='deepskyblue')\n",
    "    # plt.title(f'프로슈머유형{prediction_unit_id}번_{dt}_태양광발전량예측\\nR2: {r2:.3f}, MAE: {mae:.3f}, RMSE: {rmse:.3f}')\n",
    "    plt.title(f'프로슈머유형{prediction_unit_id}번_{dt}_태양광발전량예측')\n",
    "    if savefig: # 만약 그래프를 파일로 저장하고 싶다면, 경로 잘 지정하고, savefig 매개변수 True로 설정해주기.\n",
    "        plt.savefig(f'./VECM/프로슈머유형{prediction_unit_id}번_{dt}_24시간예측량.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4ddee-63ed-47c4-b79c-d0a48abb2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sc['earth_rotation_degree'].apply(lambda x: x if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d788c-7530-4e9f-8ab6-90a89482201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.max(x,0)\n",
    "is_consumption=0 \n",
    "test_data_block_id=574\n",
    "prediction_unit_id=5\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "endog_columns=['target','surface_solar_radiation_downwards_f','earth_rotation_degree']\n",
    "k_ar_diff=360\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "train_sc['earth_rotation_degree']=train_sc['earth_rotation_degree'].apply(lambda x: x if x>0 else 0)\n",
    "test_sc['earth_rotation_degree']=test_sc['earth_rotation_degree'].apply(lambda x: x if x>0 else 0)\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                   n_order=False, maxlags=None, deterministic='n')\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc=None, exog_columns=None, exog_coint_columns=None, steps=24, nth_day=0)\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False)\n",
    "# model_fit.plot_forecast(steps=24, n_last_obs=72,plot_conf_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd840e7-28d5-45d4-b234-d6d404a09a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deterministic=coli\n",
    "is_consumption=0\n",
    "test_data_block_id=496\n",
    "prediction_unit_id=5\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "k_ar_diff=360\n",
    "endog_columns=['target','earth_rotation_degree']\n",
    "exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                   n_order=False, maxlags=None, deterministic='coli')\n",
    "\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=24, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea487c56-fd6a-4fae-93bc-fcf7c5390913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbi 635\n",
    "is_consumption=0\n",
    "test_data_block_id=635\n",
    "prediction_unit_id=5\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "k_ar_diff=360\n",
    "endog_columns=['target','earth_rotation_degree']\n",
    "exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                   n_order=False, maxlags=None, deterministic='coli')\n",
    "\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=24, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249148d-d4e3-49a8-98e6-a89cae961d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d765828-1685-4e56-a687-dbb19bb08b61",
   "metadata": {},
   "source": [
    "## dbi 634~637 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedde458-f992-4e4f-b2e2-5af60486bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exog 고려 x\n",
    "is_consumption=0 \n",
    "test_data_block_id=634\n",
    "prediction_unit_id=5\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "endog_columns=['target','earth_rotation_degree']\n",
    "k_ar_diff=360\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                   n_order=False, maxlags=None, deterministic='n')\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc=None, exog_columns=None, exog_coint_columns=None, steps=len(test), nth_day=0)\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)\n",
    "# model_fit.plot_forecast(steps=24, n_last_obs=72,plot_conf_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b62d-ab3d-4853-a6c5-664e5ffc0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 블럭 아이디 바꾸고, exog 다 포함해서\n",
    "is_consumption=0\n",
    "test_data_block_id=634\n",
    "prediction_unit_id=5\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "k_ar_diff=360\n",
    "endog_columns=['target','earth_rotation_degree']\n",
    "exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                   n_order=False, maxlags=None, deterministic='n')\n",
    "\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=len(test), exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8cbeb8-bc0f-4460-b3c8-a3be222a873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['target_original']=y_scaler.inverse_transform(test_df[['target','prediction']])[:,0]\n",
    "test_df['prediction_original']=y_scaler.inverse_transform(test_df[['target','prediction']])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882d79b-2a0b-4cff-8b1f-9f49d2564d60",
   "metadata": {},
   "source": [
    "## 테스트: 랜덤 샘플링 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add9771-2baf-4e21-863e-1e0a5c6e5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in np.random.randint(0,60,3):\n",
    "    for d in np.random.randint(400,638,5):\n",
    "        try:\n",
    "            is_consumption=0\n",
    "            test_data_block_id=d\n",
    "            prediction_unit_id=p\n",
    "            variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "                         'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "            target_column='target'\n",
    "            \n",
    "            k_ar_diff=360\n",
    "            endog_columns=['target','earth_rotation_degree']\n",
    "            exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "            exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "            \n",
    "            train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "            \n",
    "            train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "            \n",
    "            model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                               n_order=False, maxlags=None, deterministic='n')\n",
    "            \n",
    "            y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=len(test), exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "            \n",
    "            test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee22e1c-c347-4819-8327-817026124415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for p in np.random.randint(0,60,3):\n",
    "    for d in np.random.randint(400,638,5):\n",
    "        try:\n",
    "            is_consumption=0\n",
    "            test_data_block_id=d\n",
    "            prediction_unit_id=p\n",
    "            variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "                         'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "            target_column='target'\n",
    "            \n",
    "            k_ar_diff=360\n",
    "            endog_columns=['target','earth_rotation_degree']\n",
    "            exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "            exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "            \n",
    "            train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "            \n",
    "            train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "            \n",
    "            model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                               n_order=False, maxlags=None, deterministic='n')\n",
    "            \n",
    "            y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=len(test), exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "            \n",
    "            test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3de01-7f09-4538-b0cb-d2ef5990391b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for p in np.random.randint(0,60,3):\n",
    "    for d in np.random.randint(400,638,5):\n",
    "        try:\n",
    "            is_consumption=0\n",
    "            test_data_block_id=d\n",
    "            prediction_unit_id=p\n",
    "            variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "                         'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "            target_column='target'\n",
    "            \n",
    "            k_ar_diff=360\n",
    "            endog_columns=['target','earth_rotation_degree']\n",
    "            exog_coint_columns=['direct_solar_radiation_f','cloudcover_low_f','snowfall_f']\n",
    "            exog_columns=['earth_orbit_degree','surface_solar_radiation_downwards_f','cloudcover_total_f','dewpoint_f']\n",
    "            \n",
    "            train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "            \n",
    "            train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "            \n",
    "            model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                               n_order=False, maxlags=None, deterministic='n')\n",
    "            \n",
    "            y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=len(test), exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "            \n",
    "            test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b274ae-c722-4a4c-a5fe-901efaf8822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_forecast_diff(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d0a3f-d1c7-4e48-9211-6a4098ddd5f5",
   "metadata": {},
   "source": [
    "## 내생변수: 지표면하향복사에너지 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79366a-0dc7-4032-a255-27fe395e95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column, diff=24): # \n",
    "    print(f'소비여부: {bool(is_consumption)}, 프로슈머유형: {prediction_unit_id}, 테스트날짜: {test_data_block_id}')\n",
    "    # datetime을 시간 주기 datetime 객체로 변환\n",
    "    df['datetime']=pd.to_datetime(df['datetime'])\n",
    "    df['datetime_H'] = pd.DatetimeIndex(df['datetime']).to_period('H')\n",
    "    # 조건에 맞는 데이터프레임만 가져오기 + 시간 인덱스 설정\n",
    "    df=df[((df['is_consumption']==is_consumption)&(df['prediction_unit_id']==prediction_unit_id))].set_index('datetime_H')\n",
    "    # 타겟 및 시간 컬럼을 제외한 사용 컬럼에 대한 24차분을 통해 하루전날 대비 변화량으로 표현\n",
    "    if diff:\n",
    "        data=df[variables_columns].diff(diff) # .drop(target_column, axis=1)\n",
    "        \n",
    "    # data_block_id를 따오기\n",
    "    data['data_block_id']=df['data_block_id']\n",
    "    # # 타겟 컬럼추가\n",
    "    # data[target_column]=df[target_column]\n",
    "    data=data.dropna()\n",
    "\n",
    "    # 지구 자전 컬럼 추가\n",
    "    data['earth_rotation_degree']=data.index.hour.values\n",
    "    data['earth_rotation_degree']=data['earth_rotation_degree'].apply(lambda x: x if x<=12 else 24-x)\n",
    "\n",
    "    # 지구의 태양 공전 궤도를 0~1 사이로 스케일링\n",
    "    def scale_date(year, dayofyear):\n",
    "        def solstice_date(year):\n",
    "            return 90 + 0.2422 * (year - 2000) - (year - 2000) // 4\n",
    "        \n",
    "        # 하지와 동지의 태양력 날짜를 구하기\n",
    "        summer_solstice = solstice_date(year) \n",
    "        winter_solstice = solstice_date(year) + 181\n",
    "    \n",
    "        # 태양력으로 된 날짜를 하지를 최대값으로, 동지를 최소값으로 하여 스케일링하기\n",
    "        scaled_date = (dayofyear - winter_solstice) / (summer_solstice - winter_solstice)\n",
    "    \n",
    "        # 스케일링된 날짜를 반환하기\n",
    "        return scaled_date    \n",
    "    # 지구의 태양 공전 컬럼 추가\n",
    "    data['earth_orbit_degree']=scale_date(data.index.year, data.index.dayofyear)\n",
    "    \n",
    "\n",
    "    \n",
    "    # train=data[data['data_block_id']<=369].drop('data_block_id', axis=1) ### 1년만 학습 -> 결과 구데기임. \n",
    "    train=data.drop(data[data['data_block_id']>=test_data_block_id].index).drop('data_block_id', axis=1) ### data_block_id를 바꿈. 테스트 이후의 날짜는 사용하면 안돼\n",
    "    test=data[data['data_block_id']==test_data_block_id].drop('data_block_id', axis=1) ############################ original(하루 예측용)\n",
    "    # test=data[data['data_block_id']>=test_data_block_id].drop('data_block_id', axis=1) ############################ modify(634이후 4일 예측용)\n",
    "    \n",
    "\n",
    "    print('columns: ', train.columns)\n",
    "    return train, test\n",
    "\n",
    "def scale_time_df(train, test, target_column):\n",
    "    x_scaler=StandardScaler()\n",
    "    train_sc=pd.DataFrame(x_scaler.fit_transform(train.drop(target_column, axis=1)), index=train.index, \n",
    "                                                   columns= train.drop(target_column, axis=1).columns)\n",
    "    test_sc=pd.DataFrame(x_scaler.transform(test.drop(target_column, axis=1)), index=test.index,\n",
    "                          columns=test.drop(target_column, axis=1).columns)\n",
    "\n",
    "    y_scaler=StandardScaler()\n",
    "    y_train_sc=pd.Series(y_scaler.fit_transform(train[target_column].values.reshape(-1,1))[:,0], index=train.index)\n",
    "    y_test_sc=pd.Series(y_scaler.transform(test[target_column].values.reshape(-1,1))[:,0], index=test.index)\n",
    "\n",
    "    train_sc['target']=y_train_sc\n",
    "    test_sc['target']=y_test_sc\n",
    "\n",
    "    return train_sc, test_sc, y_scaler\n",
    "\n",
    "def vecmx_modeling(train_df, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                   n_order=False, maxlags=None, deterministic='n'):\n",
    "    if n_order:\n",
    "        lag_order = select_order(train_df[endog_columns], maxlags=maxlags, deterministic=deterministic)\n",
    "        print('best aic lag order: ', lag_order.aic)\n",
    "        k_ar_diff=lag_order.aic\n",
    "\n",
    "    print('k_ar_diff: ', k_ar_diff)\n",
    "    coint_result=statsmodels.tsa.vector_ar.vecm.select_coint_rank(train_df[endog_columns], k_ar_diff=k_ar_diff, det_order=-1)\n",
    "    coint_rank=coint_result.rank\n",
    "    print('coint_rank: ', coint_rank)\n",
    "    print(coint_result)\n",
    "\n",
    "    if exog_columns and exog_coint_columns: \n",
    "        model=VECM(endog=train_df[endog_columns], exog=train_df[exog_columns], exog_coint=train_df[exog_coint_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    elif exog_columns and not exog_coint_columns:\n",
    "        model=VECM(endog=train_df[endog_columns], exog=train_df[exog_columns],\n",
    "               k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    elif not exog_columns and exog_coint_columns:\n",
    "        model=VECM(endog=train_df[endog_columns], exog_coint=train_df[exog_coint_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "    else:\n",
    "        model=VECM(endog=train_df[endog_columns],\n",
    "                   k_ar_diff=k_ar_diff, coint_rank=coint_rank, deterministic=deterministic)\n",
    "        \n",
    "    model_fit=model.fit()\n",
    "    \n",
    "    if not(exog_columns or exog_coint_columns):\n",
    "        # ax = plt.gca()  # 현재 축을 가져옵니다.\n",
    "        # ax.xaxis.set_major_locator(ticker.MultipleLocator(24))\n",
    "        model_fit.plot_forecast(steps=24, n_last_obs=96,plot_conf_int=False)\n",
    "        plt.show()\n",
    "        \n",
    "    return model_fit\n",
    "\n",
    "# 만들어진 모델로 예측해줌. 예측값을 다시 원래의 스케일로 되돌려서 반환.\n",
    "def vecmx_predicting(model_fit, y_scaler,test_sc=None,exog_columns=None, exog_coint_columns=None, steps=24, nth_day=0):\n",
    "    if exog_columns and exog_coint_columns: \n",
    "        y_pred=model_fit.predict(steps=steps, exog_coint_fc=test_sc[exog_coint_columns].iloc[nth_day*steps:nth_day*steps+steps], \n",
    "                             exog_fc=test_sc[exog_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    elif exog_columns and not exog_coint_columns:\n",
    "        y_pred=model_fit.predict(steps=steps, \n",
    "                             exog_fc=test_sc[exog_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    elif not exog_columns and exog_coint_columns:\n",
    "        y_pred=model_fit.predict(steps=steps, exog_coint_sc=test_df[exog_coint_columns].iloc[nth_day*steps:nth_day*steps+steps])\n",
    "    else:\n",
    "        y_pred=model_fit.predict(steps=steps)\n",
    "\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "# r2, mae, rmse 평가지표 뽑아주고, test용 data_block_id에 해당하는 날에 대한 그래프 그려주고, 시간을 인덱스로 실제값, 시간, 예측값을 담은 데이터 프레임 반환해줌.\n",
    "def vecmx_evaluating(test,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False): \n",
    "    \n",
    "    endog_test=test[endog_columns]\n",
    "    test_df=endog_test.iloc[nth_day*steps:nth_day*steps+steps]\n",
    "    test_df['prediction']=y_pred[:,target_location]\n",
    "\n",
    "    r2=r2_score(test_df['target'],test_df['prediction'])\n",
    "    mae=mean_absolute_error(test_df['target'],test_df['prediction'])\n",
    "    rmse= np.sqrt(mean_squared_error(test_df['target'],test_df['prediction']))\n",
    "    \n",
    "    print('r2_score: ', r2)\n",
    "    print('mae: ', mae)\n",
    "    print('rmse: ', rmse)\n",
    "    \n",
    "    dt=test_df.index[0]\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    dt=f'{year}년_{month}월_{day}일'\n",
    "\n",
    "    plt.figure(figsize=(20,8))\n",
    "    sns.lineplot(test_df, x=test_df.index.to_timestamp(), y='target', label='actual', color='tomato') # 최애 색: tamato, deepskyblue\n",
    "    sns.lineplot(test_df, x=test_df.index.to_timestamp(), y='prediction', label='prediction', color='deepskyblue')\n",
    "    # plt.title(f'프로슈머유형{prediction_unit_id}번_{dt}_태양광발전량예측\\nR2: {r2:.3f}, MAE: {mae:.3f}, RMSE: {rmse:.3f}')\n",
    "    plt.title(f'프로슈머유형{prediction_unit_id}번_{dt}_태양광발전량예측')\n",
    "    if savefig: # 만약 그래프를 파일로 저장하고 싶다면, 경로 잘 지정하고, savefig 매개변수 True로 설정해주기.\n",
    "        plt.savefig(f'./VECM/프로슈머유형{prediction_unit_id}번_{dt}_24시간예측량.jpg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fc6df-6288-483f-aa3a-fa716bc23fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 내생변수 지표면하향복사에너지 추가, 랜덤 검증\n",
    "for p in np.random.randint(0,68,5):\n",
    "    for d in np.random.randint(400,627,4):\n",
    "        try:\n",
    "            is_consumption=0 \n",
    "            test_data_block_id=d\n",
    "            prediction_unit_id=p\n",
    "            variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "                         'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "            target_column='target'\n",
    "            \n",
    "            endog_columns=['target','earth_rotation_degree','surface_solar_radiation_downwards_f']\n",
    "            k_ar_diff=360\n",
    "            \n",
    "            train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "            train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "            model_fit=vecmx_modeling(train_sc, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                               n_order=False, maxlags=None, deterministic='n')\n",
    "            y_pred=vecmx_predicting(model_fit,y_scaler,test_sc=None, exog_columns=None, exog_coint_columns=None, steps=24, nth_day=0)\n",
    "            test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False)\n",
    "        except: continue\n",
    "            # model_fit.plot_forecast(steps=24, n_last_obs=72,plot_conf_int=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d035c2-8626-40b5-a291-30ce5f7e5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외생까지 고려\n",
    "for p in np.random.randint(0,60,10):\n",
    "    # for d in np.random.randint(370,638,3):\n",
    "    for d in np.random.randint(500,638,5):\n",
    "        try:\n",
    "            is_consumption=0\n",
    "            test_data_block_id=d\n",
    "            prediction_unit_id=p\n",
    "            variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "                         'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "            target_column='target'\n",
    "            \n",
    "            k_ar_diff=360\n",
    "            endog_columns=['target','earth_rotation_degree','surface_solar_radiation_downwards_f']\n",
    "            exog_coint_columns=['direct_solar_radiation_f','cloudcover_total_f']\n",
    "            exog_columns=['earth_orbit_degree','dewpoint_f']\n",
    "            \n",
    "            train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "            \n",
    "            train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "            \n",
    "            model_fit=vecmx_modeling(train_sc, endog_columns=endog_columns, k_ar_diff=k_ar_diff, exog_coint_columns=exog_coint_columns, exog_columns=exog_columns, \n",
    "                               n_order=False, maxlags=None, deterministic='coli')\n",
    "            \n",
    "            y_pred=vecmx_predicting(model_fit,y_scaler,test_sc, steps=len(test), exog_coint_columns=exog_coint_columns, exog_columns=exog_columns)\n",
    "            \n",
    "            test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=len(test), nth_day=0, target_location=0, savefig=False)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cb4261-b944-404b-853b-e4aac3a9e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_consumption=0 \n",
    "test_data_block_id=603\n",
    "prediction_unit_id=43\n",
    "variables_columns=[ 'target', 'direct_solar_radiation_f', 'surface_solar_radiation_downwards_f', 'dewpoint_f','temperature_f',\n",
    "             'cloudcover_total_f','cloudcover_low_f','cloudcover_mid_f','cloudcover_high_f', 'snowfall_f', 'rain_f','euros_per_mwh_electricity']\n",
    "target_column='target'\n",
    "\n",
    "endog_columns=['target','surface_solar_radiation_downwards_f','earth_rotation_degree']\n",
    "k_ar_diff=360\n",
    "\n",
    "train, test= process_time_df(df, is_consumption, test_data_block_id, prediction_unit_id, variables_columns, target_column,  diff=24)\n",
    "train_sc, test_sc, y_scaler=scale_time_df(train, test, target_column)\n",
    "model_fit=vecmx_modeling(train_sc, endog_columns, k_ar_diff, exog_columns=None, exog_coint_columns=None, \n",
    "                   n_order=False, maxlags=None, deterministic='n')\n",
    "y_pred=vecmx_predicting(model_fit,y_scaler,test_sc=None, exog_columns=None, exog_coint_columns=None, steps=24, nth_day=0)\n",
    "test_df=vecmx_evaluating(test_sc,endog_columns, y_pred, prediction_unit_id, steps=24, nth_day=0, target_location=0, savefig=False)\n",
    "# model_fit.plot_forecast(steps=24, n_last_obs=72,plot_conf_int=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef11218-f8fc-48ec-9288-a8dcb49fe1c5",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df368b-a5d2-4475-84fd-73595a9f697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7cbba-833b-4518-9383-2540e54e513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.drop(['county', 'is_business', 'product_type','dt_year', 'dt_month','dt_hour', 'dt_dayofyear'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3840b7b-9519-44ac-aee0-d31afdfad2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bd31d-cbe9-4026-9b93-a9c3bf3cc947",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5859bda-c2af-4455-a4dd-996af09a6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 소비 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_cons=data[data['is_consumption']==1].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_cons):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_cons.iloc[tr_idx,1:], data_cons.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_cons.iloc[tr_idx,0], data_cons.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=LGBMRegressor(learning_rate= 0.19989546052444535, n_estimators= 300, max_depth= None, \n",
    "                        reg_alpha= 0.05673092034527474, metric= 'mae')\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_name_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/lgbm_consmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='tomato')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 소비그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/lgbm_consmodel_cv{cnt}_consumption.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/lgbm_consmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b051fa2-91c6-4a8a-8d35-94e0690dcab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 생산 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_prod=data[data['is_consumption']==0].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_prod):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_prod.iloc[tr_idx,1:], data_prod.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_prod.iloc[tr_idx,0], data_prod.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=LGBMRegressor(learning_rate= 0.19989546052444535, n_estimators= 300, max_depth= None, \n",
    "                        reg_alpha= 0.05673092034527474, metric= 'mae')\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_name_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/lgbm_prodmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='deepskyblue')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 생산그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/lgbm_prodmodel_cv{cnt}_production.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/lgbm_prodmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c04abb-9aa6-45ea-8c86-ca5d97b6d307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 유형별 소비 모델\n",
    "for p in [0,2,4,5,31,32,46,48]:\n",
    "    kfold=KFold(n_splits=7, shuffle=True)\n",
    "    r2_list=[]\n",
    "    mae_list=[]\n",
    "    rmse_list=[]\n",
    "\n",
    "    data_cons=data[data['is_consumption']==1]\n",
    "    data_consp=data_cons[data_cons['prediction_unit_id']==p].drop(['is_consumption','data_block_id', 'row_id'],axis=1)\n",
    "    cnt=0\n",
    "    for tr_idx, ts_idx in kfold.split(data_consp):\n",
    "        cnt+=1\n",
    "        x_train, x_test= data_consp.iloc[tr_idx,1:], data_consp.iloc[ts_idx,1:]\n",
    "        y_train, y_test= data_consp.iloc[tr_idx,0], data_consp.iloc[ts_idx,0]\n",
    "        \n",
    "        x_scaler=MinMaxScaler()\n",
    "        x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "        x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "        y_scaler=MinMaxScaler()\n",
    "        y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "        \n",
    "        # print(tr_idx,ts_idx)\n",
    "        # display( x_test)\n",
    "        model=LGBMRegressor(learning_rate= 0.19989546052444535, n_estimators= 300, max_depth= None, \n",
    "                            reg_alpha= 0.05673092034527474, metric= 'mae')\n",
    "        model.fit(x_train_sc, y_train_sc)\n",
    "        \n",
    "        feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_name_).sort_values(ascending=False)\n",
    "        # display(feat_imp)\n",
    "        # plt.figure(figsize=(24,8))\n",
    "        sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "        plt.title(f'{p}번유형 소비모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "        plt.savefig(f'./최종모델링/lgbm_type{p}_consmodel_cv{cnt}_feature_importances.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "        y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "        x_test['Actual']=y_test\n",
    "        x_test['Prediction']=y_pred\n",
    "        \n",
    "        r2=r2_score(y_test,y_pred)\n",
    "        mae=mean_absolute_error(y_test,y_pred)\n",
    "        rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "    \n",
    "        r2_list.append(r2)\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "    \n",
    "    \n",
    "        print(f'{cnt}회차 r2: {r2}')\n",
    "        print(f'{cnt}회차 mae: {mae}')\n",
    "        print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "        sns.scatterplot(x_test, x='Actual', y='Prediction', color='tomato')\n",
    "        sns.lineplot(x_test, x='Actual', y='Actual',color='olive')\n",
    "\n",
    "        # plt.ylabel('consumption')\n",
    "        plt.title(f'{p}번유형 소비모형 교차검증 {cnt}회차 소비그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "        plt.savefig(f'./최종모델링/lgbm_type{p}_consmodel_cv{cnt}_consumption.jpg')\n",
    "        plt.show()\n",
    "        \n",
    "        print('-'*100)\n",
    "        \n",
    "    print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "    print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "    print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "    \n",
    "    cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "    cv_scores['MAE']=mae_list\n",
    "    cv_scores['RMSE']=rmse_list\n",
    "    mean_values = cv_scores.mean()\n",
    "    cv_scores.loc['Average'] = mean_values\n",
    "    cv_scores.to_csv(f'./최종모델링/lgbm_type{p}_consmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293c0be-7f06-4129-8538-85a593f1e1d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 유형별 생산 모델\n",
    "for p in [0,2,4,5,31,32,46,48]:\n",
    "    kfold=KFold(n_splits=7, shuffle=True)\n",
    "    r2_list=[]\n",
    "    mae_list=[]\n",
    "    rmse_list=[]\n",
    "\n",
    "    data_cons=data[data['is_consumption']==0]\n",
    "    data_consp=data_cons[data_cons['prediction_unit_id']==p].drop(['is_consumption','data_block_id', 'row_id'],axis=1)\n",
    "    cnt=0\n",
    "    for tr_idx, ts_idx in kfold.split(data_consp):\n",
    "        cnt+=1\n",
    "        x_train, x_test= data_consp.iloc[tr_idx,1:], data_consp.iloc[ts_idx,1:]\n",
    "        y_train, y_test= data_consp.iloc[tr_idx,0], data_consp.iloc[ts_idx,0]\n",
    "        \n",
    "        x_scaler=MinMaxScaler()\n",
    "        x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "        x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "        y_scaler=MinMaxScaler()\n",
    "        y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "        \n",
    "        # print(tr_idx,ts_idx)\n",
    "        # display( x_test)\n",
    "        model=LGBMRegressor(learning_rate= 0.19989546052444535, n_estimators= 300, max_depth= None, \n",
    "                            reg_alpha= 0.05673092034527474, metric= 'mae')\n",
    "        model.fit(x_train_sc, y_train_sc)\n",
    "        \n",
    "        feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_name_).sort_values(ascending=False)\n",
    "        # display(feat_imp)\n",
    "        # plt.figure(figsize=(24,8))\n",
    "        sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "        plt.title(f'{p}번유형 생산모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "        plt.savefig(f'./최종모델링/lgbm_type{p}_prodmodel_cv{cnt}_feature_importances.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "        y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "        x_test['Actual']=y_test\n",
    "        x_test['Prediction']=y_pred\n",
    "        \n",
    "        r2=r2_score(y_test,y_pred)\n",
    "        mae=mean_absolute_error(y_test,y_pred)\n",
    "        rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "    \n",
    "        r2_list.append(r2)\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "    \n",
    "    \n",
    "        print(f'{cnt}회차 r2: {r2}')\n",
    "        print(f'{cnt}회차 mae: {mae}')\n",
    "        print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "        sns.scatterplot(x_test, x='Actual', y='Prediction', color='deepskyblue')\n",
    "        sns.lineplot(x_test, x='Actual', y='Actual',color='olive')\n",
    "\n",
    "        # plt.ylabel('consumption')\n",
    "        plt.title(f'{p}번유형 소비모형 교차검증 {cnt}회차 생산그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "        plt.savefig(f'./최종모델링/lgbm_type{p}_prodmodel_cv{cnt}_production.jpg')\n",
    "        plt.show()\n",
    "        \n",
    "        print('-'*100)\n",
    "        \n",
    "    print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "    print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "    print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "    \n",
    "    cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "    cv_scores['MAE']=mae_list\n",
    "    cv_scores['RMSE']=rmse_list\n",
    "    mean_values = cv_scores.mean()\n",
    "    cv_scores.loc['Average'] = mean_values\n",
    "    cv_scores.to_csv(f'./최종모델링/lgbm_type{p}_prodmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23dfffc-7428-4cf8-8759-bccd41e97f35",
   "metadata": {},
   "source": [
    "# XGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47d2d48-5c44-4ec5-bee3-0c91e2c345a4",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a92c0f-926a-4c0b-9da3-0289ddfafb59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 소비 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_cons=data[data['is_consumption']==1].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_cons):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_cons.iloc[tr_idx,1:], data_cons.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_cons.iloc[tr_idx,0], data_cons.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=XGBRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/xgb_consmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='tomato')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 소비그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/xgb_consmodel_cv{cnt}_consumption.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/xgb_consmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b37c61-d993-4c05-88c0-d7a7a6d9146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f12e6-2194-4cb3-862b-429267e34cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생산 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_prod=data[data['is_consumption']==0].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_prod):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_prod.iloc[tr_idx,1:], data_prod.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_prod.iloc[tr_idx,0], data_prod.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=XGBRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/xgb_prodmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='deepskyblue')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 생산그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/xgb_prodmodel_cv{cnt}_production.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/xgb_prodmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815def2-1220-4079-9d4f-a2a36466b283",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e36a85-5be3-46dc-a8f6-fc5fa4ebc601",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92d790-e16c-4b78-b9cd-2a757b9c1d9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 소비 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_cons=data[data['is_consumption']==1].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_cons):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_cons.iloc[tr_idx,1:], data_cons.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_cons.iloc[tr_idx,0], data_cons.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=DecisionTreeRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/dtr_consmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='tomato')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 소비그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/dtr_consmodel_cv{cnt}_consumption.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/dtr_consmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749f3d1-2e03-4d27-a032-2fe9df031831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 생산 모델\n",
    "kfold=KFold(n_splits=7, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_prod=data[data['is_consumption']==0].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_prod):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_prod.iloc[tr_idx,1:], data_prod.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_prod.iloc[tr_idx,0], data_prod.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=DecisionTreeRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # display(feat_imp)\n",
    "    # plt.figure(figsize=(24,8))\n",
    "    sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    plt.savefig(f'./최종모델링/dtr_prodmodel_cv{cnt}_feature_importances.jpg')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='deepskyblue')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 생산그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/dtr_prodmodel_cv{cnt}_production.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/dtr_prodmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20cd70-8edd-43ed-8843-74f3e5c385de",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc22519-f867-44bb-a19a-5cd5053eb143",
   "metadata": {},
   "source": [
    "## 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69245c-5707-4d7e-887f-7c7294e3f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 소비 모델\n",
    "kfold=KFold(n_splits=5, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_cons=data[data['is_consumption']==1].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_cons):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_cons.iloc[tr_idx,1:], data_cons.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_cons.iloc[tr_idx,0], data_cons.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=KNeighborsRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    # feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # # display(feat_imp)\n",
    "    # # plt.figure(figsize=(24,8))\n",
    "    # sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    # plt.title(f'소비모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    # plt.savefig(f'./최종모델링/knn_consmodel_cv{cnt}_feature_importances.jpg')\n",
    "    # plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='tomato')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'소비모형 교차검증 {cnt}회차 소비그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/knn_consmodel_cv{cnt}_consumption.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/knn_consmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40b742-4a18-4b06-9be0-c68c137be9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 생산 모델\n",
    "kfold=KFold(n_splits=5, shuffle=True)\n",
    "r2_list=[]\n",
    "mae_list=[]\n",
    "rmse_list=[]\n",
    "\n",
    "data_prod=data[data['is_consumption']==0].drop(['data_block_id','row_id'], axis=1)\n",
    "cnt=0\n",
    "for tr_idx, ts_idx in kfold.split(data_prod):\n",
    "    cnt+=1\n",
    "    x_train, x_test= data_prod.iloc[tr_idx,1:], data_prod.iloc[ts_idx,1:]\n",
    "    y_train, y_test= data_prod.iloc[tr_idx,0], data_prod.iloc[ts_idx,0]\n",
    "    \n",
    "    x_scaler=MinMaxScaler()\n",
    "    x_train_sc=pd.DataFrame(x_scaler.fit_transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    x_test_sc=pd.DataFrame(x_scaler.transform(x_test),index=x_test.index, columns=x_test.columns)\n",
    "    y_scaler=MinMaxScaler()\n",
    "    y_train_sc=y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "    \n",
    "    # print(tr_idx,ts_idx)\n",
    "    # display( x_test)\n",
    "    model=KNeighborsRegressor()\n",
    "    model.fit(x_train_sc, y_train_sc)\n",
    "    \n",
    "    # feat_imp=pd.Series(data=model.feature_importances_, index=model.feature_names_in_).sort_values(ascending=False)\n",
    "    # # display(feat_imp)\n",
    "    # # plt.figure(figsize=(24,8))\n",
    "    # sns.barplot(x= feat_imp, y=feat_imp.index)\n",
    "    # plt.title(f'생산모형 교차검증 {cnt}회차 피쳐중요도')\n",
    "    # plt.savefig(f'./최종모델링/dtr_prodmodel_cv{cnt}_feature_importances.jpg')\n",
    "    # plt.show()\n",
    "\n",
    "    y_pred=y_scaler.inverse_transform(model.predict(x_test_sc.values).reshape(-1,1))\n",
    "    x_test['Actual']=y_test\n",
    "    x_test['Prediction']=y_pred\n",
    "    \n",
    "    r2=r2_score(y_test,y_pred)\n",
    "    mae=mean_absolute_error(y_test,y_pred)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "    r2_list.append(r2)\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "\n",
    "    print(f'{cnt}회차 r2: {r2}')\n",
    "    print(f'{cnt}회차 mae: {mae}')\n",
    "    print(f'{cnt}회차 rmse: {rmse}')\n",
    "\n",
    "    sns.scatterplot(x_test, x='Actual', y='Prediction', color='deepskyblue')\n",
    "    sns.lineplot(x_test, x='Actual', y='Actual', color='olive')\n",
    "    plt.title(f'생산모형 교차검증 {cnt}회차 생산그래프\\nr2: {r2:.3f}, mae: {mae:.3f}, rmse: {rmse:.3f}')\n",
    "    plt.savefig(f'./최종모델링/dtr_prodmodel_cv{cnt}_production.jpg')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-'*100)\n",
    "    \n",
    "print(f'교차검증 평균 r2: {np.mean(r2_list)}')\n",
    "print(f'교차검증 평균 mae: {np.mean(mae_list)}')\n",
    "print(f'교차검증 평균 rmse: {np.mean(rmse_list)}')\n",
    "\n",
    "cv_scores=pd.DataFrame(np.round(r2_list,3), columns=['R_square'], index=range(1,8))\n",
    "cv_scores['MAE']=mae_list\n",
    "cv_scores['RMSE']=rmse_list\n",
    "mean_values = cv_scores.mean()\n",
    "cv_scores.loc['Average'] = mean_values\n",
    "cv_scores.to_csv('./최종모델링/dtr_prodmodel_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69ea22-86a0-4f34-8276-a4fd0eb1982b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e300d9-e476-4a56-a806-f291f11e3689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96bbc44-e343-4a2d-a03e-0e8cbb4dae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try=df.reset_index().rename(columns={'datetime':'forecast_datetime'})\n",
    "df_try['forecast_datetime']=pd.to_datetime(df_try['forecast_datetime'])\n",
    "df_try['origin_datetime']=df_try['forecast_datetime']-pd.DateOffset(hours=48)\n",
    "df_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b01ee-0280-439c-bf96-2f32d56d907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_try1=df_try[((df_try['prediction_unit_id']==5)&(df_try['is_consumption']==0)&(df_try['data_block_id']==235))][['forecast_datetime','target','origin_datetime','direct_solar_radiation_f']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d79cd-5b09-4e2b-a3a6-f666729eea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_try1.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9613e4-1835-4a7c-9f2b-2347b817f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='euros_per_mwh_electricity', bins=50)\n",
    "plt.savefig('ele_price_histo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b48c2c-74ac-4b6d-b93c-d80eaba54106",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df, x='installed_capacity', bins=50)\n",
    "plt.savefig('eic_count_histo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3a30d-44de-4369-af0f-5a9d3c38fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(df.groupby('data_block_id')[['data_block_id','direct_solar_radiation_f']].mean(), x='data_block_id', y='direct_solar_radiation_f', color='orange')\n",
    "plt.savefig('solar_line.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca94aca-ce20-485e-856e-e97196eb903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
